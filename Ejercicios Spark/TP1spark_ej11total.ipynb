{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"KHdU05jEP1EY"},"source":["# Instalo e importo librerías"]},{"cell_type":"code","metadata":{"id":"fnV5re322Wz9","colab":{"base_uri":"https://localhost:8080/"},"outputId":"25cdddae-b846-486e-e464-e146a9d01a8d","executionInfo":{"status":"ok","timestamp":1696865618085,"user_tz":180,"elapsed":13818,"user":{"displayName":"FACUNDO NAHUEL FERNANDEZ","userId":"09349471394871366588"}}},"source":["!pip install pyspark\n","!pip install -U -q PyDrive\n","!apt install openjdk-8-jdk-headless -qq\n","import os\n","os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\""],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: pyspark in /usr/local/lib/python3.10/dist-packages (3.5.0)\n","Requirement already satisfied: py4j==0.10.9.7 in /usr/local/lib/python3.10/dist-packages (from pyspark) (0.10.9.7)\n","openjdk-8-jdk-headless is already the newest version (8u382-ga-1~22.04.1).\n","0 upgraded, 0 newly installed, 0 to remove and 18 not upgraded.\n"]}]},{"cell_type":"code","metadata":{"id":"nhYIAjti3iaf","colab":{"base_uri":"https://localhost:8080/"},"outputId":"2db4fcff-bac2-46f3-a9d3-bc175f7a3a37","executionInfo":{"status":"ok","timestamp":1696865618086,"user_tz":180,"elapsed":18,"user":{"displayName":"FACUNDO NAHUEL FERNANDEZ","userId":"09349471394871366588"}}},"source":["from pydrive.auth import GoogleAuth\n","from pydrive.drive import GoogleDrive\n","from google.colab import auth\n","from oauth2client.client import GoogleCredentials\n","from pyspark.sql import *\n","from pyspark.sql.functions import *\n","from pyspark import SparkContext\n","from pyspark.sql import SQLContext\n","import pandas as pd\n","from nltk import word_tokenize\n","import nltk\n","from nltk.corpus import stopwords\n","nltk.download('punkt')\n","nltk.download('wordnet')\n","nltk.download('stopwords')\n"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["[nltk_data] Downloading package punkt to /root/nltk_data...\n","[nltk_data]   Package punkt is already up-to-date!\n","[nltk_data] Downloading package wordnet to /root/nltk_data...\n","[nltk_data]   Package wordnet is already up-to-date!\n","[nltk_data] Downloading package stopwords to /root/nltk_data...\n","[nltk_data]   Package stopwords is already up-to-date!\n"]},{"output_type":"execute_result","data":{"text/plain":["True"]},"metadata":{},"execution_count":20}]},{"cell_type":"markdown","source":["# Google Drive"],"metadata":{"id":"oWiDymDPgLil"}},{"cell_type":"code","metadata":{"id":"WmVhF9Pi3mbH"},"source":["auth.authenticate_user()\n","gauth = GoogleAuth()\n","gauth.credentials = GoogleCredentials.get_application_default()\n","drive = GoogleDrive(gauth)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Creo sesión de spark y leo csv"],"metadata":{"id":"iMoY903IgXQZ"}},{"cell_type":"code","metadata":{"id":"CoqqUqNV3wFZ"},"source":["downloaded = drive.CreateFile({'id':\"10xgOf2rORcGlcKPME3cHGHssXGzNemer\"})\n","downloaded.GetContentFile('GooglePlayStore_User_Reviews.csv')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"5ENPglW_4Cco"},"source":["spark = SparkSession.builder.getOrCreate()\n","sc = spark.sparkContext"],"execution_count":null,"outputs":[]},{"cell_type":"code","source":["sqlContext = SQLContext(sc)\n","df = sqlContext.read.option(\"delimiter\", \",\").option(\"escape\", '\"').csv('GooglePlayStore_User_Reviews.csv', header=True, inferSchema=True)\n","user_reviews = df.rdd"],"metadata":{"id":"hPSID6HBgE7H"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Ejercicio 11\n","\n","Realizar un análisis de stopwords de las reviews. Dada la frecuencia de los tokens de las reviews, mostrar los 30 tokens más frecuentes y listar del total de tokens cuales son stopwords utilizando nltk. (⭐⭐)"],"metadata":{"id":"n09UTCw4CGjQ"}},{"cell_type":"markdown","source":["Filtro las reviews nan ya que las considero un error del archivo (y además no me sirven para analizar las palabras de cada una).\n","\n","Uso distinct para eliminar reviews que se encuentran repetidas (provoca que se cuenten más de una vez palabras o tokens).\n","\n","Mapeo para quedarme solo con las reviews.\n","\n","Uso flatMap para quedarme con todos los tokens de cada review (habrá repeticiones por usar flatMap). Como tokenizer utilizo el de nltk.\n","\n","Mapeo para quedarme los tokens (todos en minúscula) como clave y 1 como valor, para desppués sumarlos con reduceByKey, quedándome así con todos los tokens y sus frecuencias.\n","\n","Cacheo porque haré más de una acción sobre esto (tomo los 30 más frecuentes y luego filtro por stopwords).\n","\n"],"metadata":{"id":"FIUv5H4vUaCh"}},{"cell_type":"code","source":["tokens_by_freq = user_reviews.filter(lambda x: (x.Translated_Review != 'nan') & (x.Translated_Review is not None)).distinct()\\\n",".map(lambda x: x.Translated_Review).flatMap(lambda x: word_tokenize(x))\\\n",".map(lambda x: (x.lower(), 1)).reduceByKey(lambda x,y: x+y).cache()"],"metadata":{"id":"wHeT24fkTer4"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["tokens_by_freq.takeOrdered(30, lambda x: -x[1])  #puedo hacer map sortBy(x[1]) o dar vuelta clave-valor y luego sortByKey, para después take(30)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"H7Le19aAoafU","outputId":"ae35a41e-f8c6-4883-af51-1d4975d7de57","executionInfo":{"status":"ok","timestamp":1696865643840,"user_tz":180,"elapsed":23299,"user":{"displayName":"FACUNDO NAHUEL FERNANDEZ","userId":"09349471394871366588"}}},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[('.', 48630),\n"," ('i', 28375),\n"," (',', 20734),\n"," ('!', 10804),\n"," ('it', 9065),\n"," ('game', 6403),\n"," ('the', 5156),\n"," (\"'s\", 4118),\n"," ('good', 4105),\n"," ('like', 4100),\n"," ('app', 3897),\n"," ('this', 3854),\n"," ('great', 3779),\n"," ('love', 3535),\n"," ('get', 3463),\n"," ('time', 3337),\n"," ('...', 2995),\n"," (\"n't\", 2958),\n"," ('?', 2751),\n"," ('would', 2523),\n"," ('really', 2335),\n"," ('even', 2151),\n"," ('not', 2056),\n"," ('ca', 2019),\n"," ('update', 1957),\n"," ('phone', 1935),\n"," ('you', 1853),\n"," ('work', 1824),\n"," (\"'m\", 1823),\n"," ('please', 1768)]"]},"metadata":{},"execution_count":26}]},{"cell_type":"code","source":["tokens_by_freq.sortBy(lambda x: x[1], ascending=False).map(lambda x: x[0]).take(30) #si los queremos sin frecuencias...(no es necesario para resolución)"],"metadata":{"id":"2TfA_yLBWAo1","colab":{"base_uri":"https://localhost:8080/"},"outputId":"93bcbe73-0af9-4d72-d92c-c01b83792dcd","executionInfo":{"status":"ok","timestamp":1696865646147,"user_tz":180,"elapsed":2340,"user":{"displayName":"FACUNDO NAHUEL FERNANDEZ","userId":"09349471394871366588"}}},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["['.',\n"," 'i',\n"," ',',\n"," '!',\n"," 'it',\n"," 'game',\n"," 'the',\n"," \"'s\",\n"," 'good',\n"," 'like',\n"," 'app',\n"," 'this',\n"," 'great',\n"," 'love',\n"," 'get',\n"," 'time',\n"," '...',\n"," \"n't\",\n"," '?',\n"," 'would',\n"," 'really',\n"," 'even',\n"," 'not',\n"," 'ca',\n"," 'update',\n"," 'phone',\n"," 'you',\n"," 'work',\n"," \"'m\",\n"," 'please']"]},"metadata":{},"execution_count":27}]},{"cell_type":"markdown","source":["Del total de tokens, obtenemos cuáles son stopwords filtrando. El map es evitable, simplemente lo hago para no mostrar la frecuencia de cada token. Puedo hacer un collect porque sé que las stopwords son un conjunto acotado de palabras."],"metadata":{"id":"7478ggYgrzwj"}},{"cell_type":"code","source":["stopwords = set(stopwords.words('english'))"],"metadata":{"id":"yugJKj5zkXNE"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["tokens_by_freq.filter(lambda x: x[0] in stopwords).map(lambda x: x[0]).collect()"],"metadata":{"id":"oy22NFsxlERs","executionInfo":{"status":"ok","timestamp":1696865647573,"user_tz":180,"elapsed":1433,"user":{"displayName":"FACUNDO NAHUEL FERNANDEZ","userId":"09349471394871366588"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"1c3311a7-239c-4000-d369-f392ec7b1670"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["['i',\n"," 'myself',\n"," 'before',\n"," 'this',\n"," 'very',\n"," 'in',\n"," 'no',\n"," 'her',\n"," 'now',\n"," 'but',\n"," 'is',\n"," 'than',\n"," 'of',\n"," 'there',\n"," 'am',\n"," 'do',\n"," 'are',\n"," 'just',\n"," 'after',\n"," 'was',\n"," 'down',\n"," 'when',\n"," 'again',\n"," 'them',\n"," 'where',\n"," 'below',\n"," 'at',\n"," 'more',\n"," 'only',\n"," 'we',\n"," 'why',\n"," 'out',\n"," 'an',\n"," 'have',\n"," 'other',\n"," 'don',\n"," 'these',\n"," 'once',\n"," 'into',\n"," 'until',\n"," 'he',\n"," 'as',\n"," 'd',\n"," 'own',\n"," 'nor',\n"," 'themselves',\n"," 'his',\n"," 'y',\n"," 'both',\n"," 's',\n"," 'during',\n"," 'above',\n"," 'further',\n"," 'against',\n"," 'ourselves',\n"," 'wasn',\n"," 'couldn',\n"," 'yourselves',\n"," 'yours',\n"," 've',\n"," 'doesn',\n"," 'theirs',\n"," 'that',\n"," 'because',\n"," 'it',\n"," 'not',\n"," 'my',\n"," 'she',\n"," 'you',\n"," 'up',\n"," 'does',\n"," 'its',\n"," 'the',\n"," 'can',\n"," 'so',\n"," 'to',\n"," 'and',\n"," 'be',\n"," 'or',\n"," 'same',\n"," 'for',\n"," 'by',\n"," 'on',\n"," 'has',\n"," 'been',\n"," 'me',\n"," 'if',\n"," 'a',\n"," 'should',\n"," 'which',\n"," 'all',\n"," 'what',\n"," 'they',\n"," 'few',\n"," 'from',\n"," 'with',\n"," 'had',\n"," 'most',\n"," 'those',\n"," 'then',\n"," 'how',\n"," 'did',\n"," 'your',\n"," 'too',\n"," 'who',\n"," 't',\n"," 'will',\n"," 'about',\n"," 'such',\n"," 'while',\n"," 'doing',\n"," 'any',\n"," 'itself',\n"," 'some',\n"," 'over',\n"," 'were',\n"," 'herself',\n"," 'him',\n"," 'off',\n"," 'through',\n"," 'here',\n"," 'having',\n"," 'being',\n"," 'm',\n"," 'yourself',\n"," 'each',\n"," 'their',\n"," 're',\n"," 'between',\n"," 'o',\n"," 'under',\n"," 'whom',\n"," 'himself',\n"," 'won',\n"," 'our',\n"," 'll',\n"," 'ma']"]},"metadata":{},"execution_count":29}]},{"cell_type":"markdown","source":["Por \"culpa\" de las abreviaciones nos quedan separados \"n't\" de \"not\", nos queda \"'m\" en vez de \"am\", \"'s\" en vez de \"is\" y algo similar sucede con \"ca\", que probablemente queda así porque el tokenizer separa \"can't\" literalmente en dos, en vez de considerar que realmente es \"cannot\".\n","\n","Tanto am, is como can están entre las stopwords pero por aparecer abreviadas no se tienen en cuenta.\n","\n","Not debería tener mayor frecuencia juntado los not y los n't."],"metadata":{"id":"ItDhqZ-upTbL"}},{"cell_type":"markdown","source":["Podría haber eliminado símbolos (como el punto o la coma, que quedaron entre los primeros) de las reviews para obtener resultados solo con palabras, pero no sé si era la idea del ejercicio ya que estos pueden ser considerados como tokens."],"metadata":{"id":"KvzVEM5gp4rD"}}]}